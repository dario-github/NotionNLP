{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acknowledged-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import arrow\n",
    "import pprint\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "from functools import reduce\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955705ac-fe04-41aa-b423-4348f1a83ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from utils.log import config_log\n",
    "\n",
    "config_log(\n",
    "        \"notion_api\",\n",
    "        \"DBtexts\",\n",
    "        log_root='./logs',\n",
    "        print_terminal=True,\n",
    "        enable_monitor=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cba7a0-735a-4654-afae-f45d6ae30ec0",
   "metadata": {},
   "source": [
    "## 环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1b96ef-658f-4265-bc71-190b29e6bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取token：https://www.notion.so/my-integrations/\n",
    "token = open(\"./NOTION_TOKEN\", \"r\").readlines()[0]\n",
    "# notion_version =  \"2021-08-16\"\n",
    "notion_version = \"2022-06-28\"\n",
    "\n",
    "notion_header = {\"Authorization\": f\"Bearer {token}\",\n",
    "                 \"Notion-Version\": notion_version,\n",
    "                 \"Content-Type\": \"application/json\",\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7707f0-e794-4333-8663-d55b77762b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要读取的database ID\n",
    "database_id = 'a2594f51053a47b3a58a171017ea0435'\n",
    "\n",
    "# 筛选 property，这里的 Label 是上述 database 中的属性\n",
    "extra_data = {\"filter\": {\"and\": [{\"property\": \"Label\",\n",
    "                                  \"multi_select\": {\"is_not_empty\": True}},],},\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb3887-99e6-4621-9593-d51117f59312",
   "metadata": {},
   "source": [
    "## 读取数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "293a1282-acd1-4410-8bfa-17c678bce36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class NotionDBText:\n",
    "    \"\"\"\n",
    "    读取数据库中所有富文本信息\n",
    "    \"\"\"\n",
    "    def __init__(self, notion_header: dict, database_id: str, extra_data: dict = dict()):\n",
    "        self.header = notion_header\n",
    "        self.database_id = database_id\n",
    "        self.extra_data = extra_data\n",
    "        self.total_texts, self.total_blocks, self.total_pages = [[]] * 3\n",
    "        self.block_types = [\"paragraph\", \"bulleted_list_item\", \"numbered_list_item\", \n",
    "                            \"toggle\", \"to_do\", \"quote\", \n",
    "                            \"callout\", \"synced_block\", \"template\", \n",
    "                            \"column\", \"child_page\", \"child_database\", \"table\",\n",
    "                            \"heading_1\",\"heading_2\",\"heading_3\"]\n",
    "    \n",
    "    def read(self):\n",
    "        self.total_pages = self.read_pages()\n",
    "        self.total_blocks = self.read_blocks(self.total_pages)\n",
    "        self.total_texts = self.read_rich_text(self.total_blocks)\n",
    "        \n",
    "    def read_pages(self):\n",
    "        \"\"\"\n",
    "        读取database中所有pages\n",
    "        \"\"\"\n",
    "        total_pages = []\n",
    "        has_more = True\n",
    "        next_cursor = ''\n",
    "        # 有下一页时，继续读取\n",
    "        while has_more:\n",
    "            if next_cursor:\n",
    "                extra_data['start_cursor'] = next_cursor\n",
    "            r_database = requests.post(\n",
    "                url=f\"https://api.notion.com/v1/databases/{self.database_id}/query\",\n",
    "                headers=self.header,\n",
    "                data=json.dumps(self.extra_data),\n",
    "            )\n",
    "            respond = json.loads(r_database.text)\n",
    "            total_pages.extend(respond[\"results\"])\n",
    "            has_more = respond['has_more']\n",
    "            next_cursor = respond['next_cursor']\n",
    "        logging.info(f'{len(total_pages)} pages when {arrow.now()}')\n",
    "        return total_pages\n",
    "    \n",
    "    def read_blocks(self, pages: List):\n",
    "        \"\"\"\n",
    "        读取pages中所有blocks\n",
    "        \"\"\"\n",
    "        total_blocks = []\n",
    "        for page in tqdm(pages, desc='read blocks'):\n",
    "            page_id = page[\"id\"]\n",
    "            r_page = requests.get(\n",
    "                        url=f\"https://api.notion.com/v1/blocks/{page_id}/children\",\n",
    "                        headers=self.header,\n",
    "                        )\n",
    "            total_blocks.append(json.loads(r_page.text).get(\"results\", []))\n",
    "        return total_blocks\n",
    "        \n",
    "    def read_rich_text(self, blocks: List):\n",
    "        \"\"\"\n",
    "        读取blocks中所有rich text\n",
    "        \"\"\"\n",
    "        total_texts = []\n",
    "        for page_blocks in blocks:\n",
    "            page_texts = []\n",
    "            for block in page_blocks:\n",
    "                if block['type'] not in self.block_types:\n",
    "                    logging.warning(block['type'] + ' not in type list')\n",
    "                    continue\n",
    "                try:\n",
    "                    page_texts.extend([x['plain_text'] for x in block[block['type']]['rich_text']])\n",
    "                except Exception as e:\n",
    "                    logging.error(block['type'] + '|' + json.dumps(block[block['type']]))\n",
    "            total_texts.append(page_texts)\n",
    "        return total_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05fa63bf-b675-438d-8335-705ac63ab580",
   "metadata": {},
   "outputs": [],
   "source": [
    "notion_db = NotionDBText(notion_header, database_id, extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d34f240-a760-414d-ba5c-b38edd9ecc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-29 05:26:14.616] [INFO] [298233] [410687785.py] [42] [67 pages when 2023-01-29T05:26:14.616211+00:00]\n",
      "read blocks: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:26<00:00,  2.52it/s]\n",
      "[2023-01-29 05:26:41.260] [WARNING] [298233] [410687785.py] [68] [divider not in type list]\n",
      "[2023-01-29 05:26:41.264] [WARNING] [298233] [410687785.py] [68] [divider not in type list]\n",
      "[2023-01-29 05:26:41.267] [WARNING] [298233] [410687785.py] [68] [image not in type list]\n",
      "[2023-01-29 05:26:41.268] [WARNING] [298233] [410687785.py] [68] [table_of_contents not in type list]\n",
      "[2023-01-29 05:26:41.272] [WARNING] [298233] [410687785.py] [68] [link_to_page not in type list]\n"
     ]
    }
   ],
   "source": [
    "notion_db.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27820be7-444b-4811-aed4-50e87cbd1e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['外部的数据大家都可以用，怎样能把MP的独有数据利用起来？或者设计独有的数据收集？', '数据是否能够按照博弈论，分类成外部公开、半公开数据、独家数据？']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notion_db.total_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d3e1f-2d37-46f4-979e-644fa11b4549",
   "metadata": {},
   "source": [
    "## 分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83f7b80f-e62c-4f9f-af94-0d80b353bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn jieba -q\n",
    "\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "# 标点符号\n",
    "import sys\n",
    "from unicodedata import category\n",
    "codepoints = range(sys.maxunicode + 1)\n",
    "punctuation = {c for k in codepoints if category(c := chr(k)).startswith(\"P\")}\n",
    "\n",
    "# 停用词\n",
    "from glob import glob\n",
    "stopfiles = glob(\"./stopwords/*stopwords.txt\")\n",
    "stopwords = reduce(lambda x,y: x.union(y), [set([x.strip() for x in open(file, \"r\").readlines()]) for file in stopfiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "formed-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stopwords(word):\n",
    "    return word in stopwords \\\n",
    "        or word in punctuation \\\n",
    "        or word.isdigit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bacd1-196c-4fcd-8434-a856087c2667",
   "metadata": {},
   "source": [
    "### 分词、清洗、建立映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c0a3e24-bed7-4ac0-b30c-b70a34750a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functional import seq\n",
    "text_list = [text for item in notion_db.total_texts for text in item]\n",
    "# text_list = notion_db.total_texts\n",
    "# 分词\n",
    "split_text_list = [jieba.lcut(text, HMM=True) for text in text_list]\n",
    "# 剔除停用词\n",
    "sequence = seq(split_text_list).map(lambda sent: [word for word in sent if not check_stopwords(word)])\n",
    "\n",
    "# 包含的词\n",
    "uniqueWords = (sequence\n",
    "               .map(lambda sent: set(sent))\n",
    "               .reduce(lambda x, y: x.union(y))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fd26cfe-f7f6-401c-920a-73bfc4cd9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词 --> 句子 查询字典\n",
    "word2sents = {word.lower(): set() for word in uniqueWords}\n",
    "\n",
    "for text in text_list:\n",
    "    for word in uniqueWords:\n",
    "        if word in text:\n",
    "            word2sents[word.lower()].add(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-international",
   "metadata": {},
   "source": [
    "### 使用标准tf-idf工具来分析\n",
    "\n",
    "todo:\n",
    "\n",
    "句子全混合在同一个列表里肯定不对，要按文档分开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "broke-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(sequence.map(lambda x: \" \".join(x)).to_list())\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "accepted-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果写入文件\n",
    "df.max(axis=0).sort_values(key=lambda x: -x).to_csv(\"./tf_idf_topic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "pressed-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untitled\n",
      "{'Untitled'}\n",
      "----------\n",
      "节奏\n",
      "{'进入节奏'}\n",
      "----------\n",
      "分享\n",
      "{'分享'}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 检查高频词\n",
    "for word in df.max(axis=0).sort_values(key=lambda x: -x).head(3).index:\n",
    "    print(word)\n",
    "    print(word2sents[word])\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-violation",
   "metadata": {},
   "source": [
    "### 自定义(不是tf*idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cheap-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = (sequence\n",
    "               .map(lambda sent: set(sent))\n",
    "               .reduce(lambda x, y: x.union(y))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fitting-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "analyzed-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75bd4cc-5aac-4b60-b227-d85b5b568f26",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b3a4a-6b52-4cc0-971e-17900f6270db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
