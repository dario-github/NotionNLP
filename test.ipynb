{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acknowledged-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import arrow\n",
    "import pprint\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "from functools import reduce\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955705ac-fe04-41aa-b423-4348f1a83ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from utils.log import config_log\n",
    "\n",
    "config_log(\n",
    "        \"notion_api\",\n",
    "        \"DBtexts\",\n",
    "        log_root='./logs',\n",
    "        print_terminal=True,\n",
    "        enable_monitor=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cba7a0-735a-4654-afae-f45d6ae30ec0",
   "metadata": {},
   "source": [
    "## 环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1b96ef-658f-4265-bc71-190b29e6bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取token：https://www.notion.so/my-integrations/\n",
    "token = open(\"./NOTION_TOKEN\", \"r\").readlines()[0]\n",
    "# notion_version =  \"2021-08-16\"\n",
    "notion_version = \"2022-06-28\"\n",
    "\n",
    "notion_header = {\"Authorization\": f\"Bearer {token}\",\n",
    "                 \"Notion-Version\": notion_version,\n",
    "                 \"Content-Type\": \"application/json\",\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7707f0-e794-4333-8663-d55b77762b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要读取的database ID\n",
    "database_id = 'a2594f51053a47b3a58a171017ea0435'\n",
    "\n",
    "# 筛选 property，这里的 Label 是上述 database 中的属性\n",
    "extra_data = {\"filter\": {\"and\": [{\"property\": \"Label\",\n",
    "                                  \"multi_select\": {\"is_not_empty\": True}},],},\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb3887-99e6-4621-9593-d51117f59312",
   "metadata": {},
   "source": [
    "## 读取数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "293a1282-acd1-4410-8bfa-17c678bce36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class NotionDBText:\n",
    "    \"\"\"\n",
    "    读取数据库中所有富文本信息\n",
    "    \"\"\"\n",
    "    def __init__(self, notion_header: dict, database_id: str, extra_data: dict = dict()):\n",
    "        self.header = notion_header\n",
    "        self.database_id = database_id\n",
    "        self.extra_data = extra_data\n",
    "        self.total_texts, self.total_blocks, self.total_pages = [[]] * 3\n",
    "        self.block_types = [\"paragraph\", \"bulleted_list_item\", \"numbered_list_item\", \n",
    "                            \"toggle\", \"to_do\", \"quote\", \n",
    "                            \"callout\", \"synced_block\", \"template\", \n",
    "                            \"column\", \"child_page\", \"child_database\", \"table\",\n",
    "                            \"heading_1\",\"heading_2\",\"heading_3\"]\n",
    "    \n",
    "    def read(self):\n",
    "        self.total_pages = self.read_pages()\n",
    "        self.total_blocks = self.read_blocks(self.total_pages)\n",
    "        self.total_texts = self.read_rich_text(self.total_blocks)\n",
    "        \n",
    "    def read_pages(self):\n",
    "        \"\"\"\n",
    "        读取database中所有pages\n",
    "        \"\"\"\n",
    "        total_pages = []\n",
    "        has_more = True\n",
    "        next_cursor = ''\n",
    "        # 有下一页时，继续读取\n",
    "        while has_more:\n",
    "            if next_cursor:\n",
    "                extra_data['start_cursor'] = next_cursor\n",
    "            r_database = requests.post(\n",
    "                url=f\"https://api.notion.com/v1/databases/{self.database_id}/query\",\n",
    "                headers=self.header,\n",
    "                data=json.dumps(self.extra_data),\n",
    "            )\n",
    "            respond = json.loads(r_database.text)\n",
    "            total_pages.extend(respond[\"results\"])\n",
    "            has_more = respond['has_more']\n",
    "            next_cursor = respond['next_cursor']\n",
    "        logging.info(f'{len(total_pages)} pages when {arrow.now()}')\n",
    "        return total_pages\n",
    "    \n",
    "    def read_blocks(self, pages: List):\n",
    "        \"\"\"\n",
    "        读取pages中所有blocks\n",
    "        \"\"\"\n",
    "        total_blocks = []\n",
    "        for page in tqdm(pages, desc='read blocks'):\n",
    "            page_id = page[\"id\"]\n",
    "            r_page = requests.get(\n",
    "                        url=f\"https://api.notion.com/v1/blocks/{page_id}/children\",\n",
    "                        headers=self.header,\n",
    "                        )\n",
    "            total_blocks.append(json.loads(r_page.text).get(\"results\", []))\n",
    "        return total_blocks\n",
    "        \n",
    "    def read_rich_text(self, blocks: List):\n",
    "        \"\"\"\n",
    "        读取blocks中所有rich text\n",
    "        \"\"\"\n",
    "        total_texts = []\n",
    "        for page_blocks in blocks:\n",
    "            page_texts = []\n",
    "            for block in page_blocks:\n",
    "                if block['type'] not in self.block_types:\n",
    "                    logging.warning(block['type'] + ' not in type list')\n",
    "                    continue\n",
    "                try:\n",
    "                    page_texts.extend([x['plain_text'] for x in block[block['type']]['rich_text']])\n",
    "                except Exception as e:\n",
    "                    logging.error(block['type'] + '|' + json.dumps(block[block['type']]))\n",
    "            total_texts.append(page_texts)\n",
    "        return total_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05fa63bf-b675-438d-8335-705ac63ab580",
   "metadata": {},
   "outputs": [],
   "source": [
    "notion_db = NotionDBText(notion_header, database_id, extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d34f240-a760-414d-ba5c-b38edd9ecc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-29 05:26:14.616] [INFO] [298233] [410687785.py] [42] [67 pages when 2023-01-29T05:26:14.616211+00:00]\n",
      "read blocks: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:26<00:00,  2.52it/s]\n",
      "[2023-01-29 05:26:41.260] [WARNING] [298233] [410687785.py] [68] [divider not in type list]\n",
      "[2023-01-29 05:26:41.264] [WARNING] [298233] [410687785.py] [68] [divider not in type list]\n",
      "[2023-01-29 05:26:41.267] [WARNING] [298233] [410687785.py] [68] [image not in type list]\n",
      "[2023-01-29 05:26:41.268] [WARNING] [298233] [410687785.py] [68] [table_of_contents not in type list]\n",
      "[2023-01-29 05:26:41.272] [WARNING] [298233] [410687785.py] [68] [link_to_page not in type list]\n"
     ]
    }
   ],
   "source": [
    "notion_db.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27820be7-444b-4811-aed4-50e87cbd1e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['外部的数据大家都可以用，怎样能把MP的独有数据利用起来？或者设计独有的数据收集？', '数据是否能够按照博弈论，分类成外部公开、半公开数据、独家数据？']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notion_db.total_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d3e1f-2d37-46f4-979e-644fa11b4549",
   "metadata": {},
   "source": [
    "## 分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "83f7b80f-e62c-4f9f-af94-0d80b353bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn jieba -q\n",
    "\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "# 标点符号\n",
    "import sys\n",
    "from unicodedata import category\n",
    "codepoints = range(sys.maxunicode + 1)\n",
    "punctuation = {c for k in codepoints if category(c := chr(k)).startswith(\"P\")}\n",
    "\n",
    "# 停用词\n",
    "from glob import glob\n",
    "stopfiles = glob(\"./stopwords/*stopwords.txt\")\n",
    "stopwords = reduce(lambda x,y: x.union(y), [set([x.strip() for x in open(file, \"r\").readlines()]) for file in stopfiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "formed-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stopwords(word):\n",
    "    return word in stopwords \\\n",
    "             or word.isdigit() \\\n",
    "             or word in punctuation \\\n",
    "             or not word.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bacd1-196c-4fcd-8434-a856087c2667",
   "metadata": {},
   "source": [
    "### 分词、清洗、建立映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4c0a3e24-bed7-4ac0-b30c-b70a34750a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functional import seq\n",
    "text_list = [text for item in notion_db.total_texts for text in item]\n",
    "# 分词\n",
    "split_text_list = [jieba.lcut(text, HMM=True) for text in text_list]\n",
    "# 剔除停用词\n",
    "sequence = seq(split_text_list).map(lambda sent: [word for word in sent if not check_stopwords(word)])\n",
    "# sequence = seq(split_text_list)\n",
    "\n",
    "# 包含的词\n",
    "uniqueWords = (sequence\n",
    "               .map(lambda sent: set(sent))\n",
    "               .reduce(lambda x, y: x.union(y))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3fd26cfe-f7f6-401c-920a-73bfc4cd9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词 --> 句子 查询字典\n",
    "word2sents = {word.lower(): [] for word in uniqueWords}\n",
    "\n",
    "for text in text_list:\n",
    "    for word in uniqueWords:\n",
    "        if word in text:\n",
    "            word2sents[word.lower()].append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-international",
   "metadata": {},
   "source": [
    "### 使用标准tf-idf工具来分析\n",
    "\n",
    "todo:\n",
    "\n",
    "句子全混合在同一个列表里肯定不对，要按文档分开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "broke-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(sequence.map(lambda x: \" \".join(x)).to_list())\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "denselist = vectors.todense().tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67d154-63a7-436c-9f2e-84d7673fc1ec",
   "metadata": {},
   "source": [
    "#### 按不同统计方法逆序输出所有词的tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7c7b850b-e922-48aa-baa1-e7e9c8eae465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剔除最大最小值，求均值\n",
    "df_drop_maxmin = df.copy()\n",
    "for col in df.columns:\n",
    "    df_drop_maxmin[col] = df[col][df[col].between(df[col].min(), df[col].max())]\n",
    "    df_drop_maxmin[col].dropna(inplace=True)\n",
    "df_drop_maxmin.mean().sort_values(ascending=False).to_csv(\"./tf_idf_top.drop_maxmin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "accepted-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大值\n",
    "df.max(axis=0).sort_values(ascending=False).to_csv(\"./tf_idf_top.max.csv\")\n",
    "# 求和\n",
    "df.sum(axis=0).sort_values(ascending=False).to_csv(\"./tf_idf_top.sum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "pressed-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "知识\n",
      "['追求伟大的知识分子，癫狂、荒谬', '我需要解决什么问题？精力有限，需要管理想要了解的问题，而不是知识', '空洞的知识没有用（例如同花顺的知识图谱，几百万三元组，吃灰）', '如果你本身没有需要解决的问题（或者说专注研究的领域），那么知识管理只是个伪命题', '我们需要管理的不是知识，而是自己的精力和想要了解的问题。', '你的知识应该是像一条大河一样，有上游涓涓的溪流，也能灌溉更多的良田。', '如果要将知识讲给别人，应该怎么组织结构？把它输出为教案形式', '知识', '阅读论文、网页等短中篇文献，整理归纳后导出工作区PDF到notion存档，链接个人知识网络', '文献的知识密度要大', '存档数据库、整合前三者，输出自己的思维和成体系的知识', '纯知识：', '投资能力（量化工具、方法，股票知识）、']\n",
      "----------\n",
      "思考\n",
      "['我是一个很喜欢思考和研究时事政治的答主。但我从来不写时事政治感悟。\\n我觉得，在现实中讨论任何政治有关的言论都是极其愚蠢的。你支持A，得罪B，支持B得罪A。\\n', '可能是慢？更多时间思考？', '压制收藏的欲望，必须用大脑去思考，吸收有用信息，然后输出为自己的内容，这样才能将', '关于社会核心本质的思考', '只能作为思考的中间产物', '可以批注二度思考nobility的手写笔记，组织成结构', 'xmind（思考）', '周报思考', '如果有轮回转世，那中国民间信仰的敬天崇祖就失去了标的，毕竟祖宗都转世去了，烧钱给谁？所以一切相信有轮回转世的宗教，比如佛教、伊斯兰教、基督教、印度教，在中国都面临着与本土信仰解释性发生冲突的问题。很遗憾，最后被改变的是本土文明，道教原本是不讲轮回的，崇尚长生，只修这一世，结果受佛教影响太深，几乎所有道教宗派现在都认同轮回转世。其中的矛盾点不知前人是否思考过，也许是刻意回避了，因为两个都解释不了的东西，即使矛盾也影响不大，无法对自己证真，自然就无法对别人证伪🌝', '没有人有权以“思考能力不足”为由，剥夺他人的权利。何为“独立思考能力”，它的界限在哪里。', '开放式办公场所的弊病之一，就是嘈杂的外部环境会干扰思考，即使戴着降噪还是很难完全屏蔽人声。对算法这种需要沉浸思考的工种很不友好。']\n",
      "----------\n",
      "时间\n",
      "['。\\n你说自己无神论，有神论的觉得的你是傻逼以后给你下绊子，你信神，无神论的觉得你脑子有问题。\\n你无论支持哪一派，你都无利可图，你无论支持哪一派，你都要倒霉。\\n问，狮子和大灰狼选举，你是小绵羊，你投票哪个？\\n答，小绵羊投票打架打赢的，狮子大灰狼死里打才好，都半死不活，小羊生活最幸福快乐。投票投打赢的那个，告诉他，大哥我支持你，你看是我给你投票上台的\\n别人讨论国际关系打嘴炮时候，我是研究玉米国，大豆国一旦和中国关系不好，制裁玉米国大豆国，那就炒玉米大豆，和铁矿国关系不好了，不进口铁矿国东西，原材料就涨价。\\n推荐大家只关心和自己利益相关衣食住行教育，房价等。和自己无关的事情少参与，参与和自己无关的事情就要倒霉。\\n那些不发财的破事我不想写，也不爱写。比如，哪个国家更富强更厉害，更优秀等，画画讽刺别国，哪些领域又赢了，都是浪费读者时间。\\n刷考研政治肖秀荣的题，我很疑惑，10年的事情应该在中国近代史的考纲内，为啥考研不考那十年的事情。\\n抗美援朝是考研政治重点，为啥出题不考彭德怀。\\n查了一下彭德怀的晚年，他非常坚强，彭德怀真是中国的脊梁。\\n1974年11月29日，由于长期的摧残和折磨，彭德怀在北京逝世。\\n1978年12月，中共十一届三中全会为彭德怀平反昭雪，恢复名誉。\\n你看，输的人考试都不考，考试就考赢的人。\\n我作为医科大学临床医学出身的答主，我预判新冠有关的很准的，但是我真不敢写和新冠有关的文章。\\n我只默默地写了，我是新冠期间怎么做的，怎么行动的，怎么发财的，我和粉丝利益最大化。\\n武汉逃生，医院辞职修冷库，炒粮食，考律师证。但我从来不写和新冠病毒有关的文章。\\n我姥姥姥爷，奶和日语系前女友等嫡系相信我医术好。因为我学医啥病都能治，所以他们怕疼所以不想打预防针，我劝不动。我读者粉丝打预防针，不要像我家人一样怕疼。\\n我无论做的还是写的，都经得起时间的检验。\\n我很鄙视那些，出租车司机那种高谈阔论的讨论时事政治。\\n闷声发大财不香么？\\n比如这个被拘留的，不冤枉。\\n关于防疫，支持保经济想隐瞒疫情的训诫了李哥。\\n想严防死守病毒，经济下滑点没事的拘留了老师。\\n领导让你做什么，你做什么就对了。\\n作为老师你无论支持谁反对谁都不会给你涨一分钱工资。写那些东西浪费时间干嘛？', '社会设计时间，对待人', '暴政，指统治者利用时间精细化管控，进一步压榨劳动者', '谁控制时间分配和解释，谁就是统治者', '唯一等价物（时间）', '失去了对时间应有的感知能力', '可能是慢？更多时间思考？', '番茄工作法核心意义：复盘、发现问题、降低压迫感\\n自由：时间的主动权', '将一天中的有效时间划分为无数个 15 分钟，以此准确安排自己的工作和生活，并每天复盘自己的执行情况。发现问题，解决问题，是番茄工作法任务规划和时间评估的意义所在。', '成年人的自由不是疲于奔命，而是努力生活，重夺时间的主动权。']\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 检查高频词\n",
    "for word in df.sum(axis=0).sort_values(ascending=False).head(3).index:\n",
    "    print(word)\n",
    "    print(word2sents[word])\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-violation",
   "metadata": {},
   "source": [
    "### 自定义(不是tf*idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cheap-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = (sequence\n",
    "               .map(lambda sent: set(sent))\n",
    "               .reduce(lambda x, y: x.union(y))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fitting-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "analyzed-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75bd4cc-5aac-4b60-b227-d85b5b568f26",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b3a4a-6b52-4cc0-971e-17900f6270db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
